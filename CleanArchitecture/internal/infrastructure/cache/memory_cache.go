package cache

import (
	"context"
	"strings"
	"sync"
	"time"
	
	"clean-url-shortener/pkg/cache"
	"clean-url-shortener/pkg/logger"
)

// üìö –ò–ó–£–ß–ò–¢–¨: In-Memory –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
// https://en.wikipedia.org/wiki/Cache_(computing)
// https://github.com/patrickmn/go-cache
// https://github.com/allegro/bigcache
//
// –ö–û–ì–î–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–¢–¨ IN-MEMORY CACHE:
// 1. –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
// 2. –ù–µ–±–æ–ª—å—à–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (single instance)
// 3. –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (–Ω–µ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏)
// 4. –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ Redis
//
// –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø IN-MEMORY CACHE:
// 1. –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ (–∫–∞–∂–¥—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∏–º–µ–µ—Ç —Å–≤–æ–π –∫—ç—à)
// 2. –î–∞–Ω–Ω—ã–µ —Ç–µ—Ä—è—é—Ç—Å—è –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
// 3. –ü–æ—Ç—Ä–µ–±–ª—è–µ—Ç –ø–∞–º—è—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
// 4. –ù–µ—Ç –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏

// cacheItem —ç–ª–µ–º–µ–Ω—Ç –∫—ç—à–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
type cacheItem struct {
	data      []byte    // –ó–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
	expiresAt time.Time // –í—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è
	createdAt time.Time // –í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è
}

// isExpired –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å—Ç–µ–∫ –ª–∏ —ç–ª–µ–º–µ–Ω—Ç –∫—ç—à–∞
func (item *cacheItem) isExpired() bool {
	return time.Now().After(item.expiresAt)
}

// MemoryCache —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ –≤ –ø–∞–º—è—Ç–∏
// üìö –ò–ó–£–ß–ò–¢–¨: Thread-safe programming –≤ Go
// https://golang.org/doc/effective_go.html#sharing
// https://pkg.go.dev/sync
type MemoryCache struct {
	// items —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫—ç—à–∞
	items map[string]*cacheItem
	
	// mutex –¥–ª—è thread-safe –æ–ø–µ—Ä–∞—Ü–∏–π
	// –í–ê–ñ–ù–û: –í Go –Ω—É–∂–Ω–æ –∑–∞—â–∏—â–∞—Ç—å –¥–æ—Å—Ç—É–ø –∫ shared state
	mutex sync.RWMutex
	
	// logger –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π –∫—ç—à–∞
	logger logger.Logger
	
	// cleanupInterval –∏–Ω—Ç–µ—Ä–≤–∞–ª –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–µ–∫—à–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
	cleanupInterval time.Duration
	
	// stopCleanup –∫–∞–Ω–∞–ª –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ñ–æ–Ω–æ–≤–æ–π –æ—á–∏—Å—Ç–∫–∏
	stopCleanup chan struct{}
	
	// metrics –º–µ—Ç—Ä–∏–∫–∏ –∫—ç—à–∞
	metrics *cacheMetrics
}

// cacheMetrics –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∫—ç—à–∞
type cacheMetrics struct {
	hits   int64
	misses int64
	errors int64
	mutex  sync.RWMutex
}

// NewMemoryCache —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—ã–π in-memory –∫—ç—à
func NewMemoryCache(logger logger.Logger, cleanupInterval time.Duration) cache.Cache {
	mc := &MemoryCache{
		items:           make(map[string]*cacheItem),
		logger:          logger.InfrastructureLogger().With("component", "memory_cache"),
		cleanupInterval: cleanupInterval,
		stopCleanup:     make(chan struct{}),
		metrics:         &cacheMetrics{},
	}
	
	// –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—É—é –æ—á–∏—Å—Ç–∫—É –∏—Å—Ç–µ–∫—à–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
	go mc.startCleanup()
	
	mc.logger.Info("Memory cache initialized", 
		"cleanup_interval", cleanupInterval)
	
	return mc
}

// Get –ø–æ–ª—É—á–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É
func (mc *MemoryCache) Get(ctx context.Context, key string) ([]byte, error) {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()
	
	item, exists := mc.items[key]
	if !exists {
		mc.recordMiss()
		mc.logger.Debug("Cache miss", "key", key)
		return nil, cache.ErrCacheKeyNotFound
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–µ—á–µ–Ω–∏–µ TTL
	if item.isExpired() {
		mc.recordMiss()
		mc.logger.Debug("Cache expired", "key", key, "expired_at", item.expiresAt)
		
		// –£–¥–∞–ª—è–µ–º –∏—Å—Ç–µ–∫—à–∏–π —ç–ª–µ–º–µ–Ω—Ç (—Ç—Ä–µ–±—É–µ—Ç write lock)
		mc.mutex.RUnlock()
		mc.mutex.Lock()
		delete(mc.items, key)
		mc.mutex.Unlock()
		mc.mutex.RLock()
		
		return nil, cache.ErrCacheKeyNotFound
	}
	
	mc.recordHit()
	mc.logger.Debug("Cache hit", "key", key, "data_size", len(item.data))
	
	// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
	result := make([]byte, len(item.data))
	copy(result, item.data)
	
	return result, nil
}

// Set —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Å TTL
func (mc *MemoryCache) Set(ctx context.Context, key string, value []byte, ttl time.Duration) error {
	if ttl <= 0 {
		return cache.ErrInvalidTTL
	}
	
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	
	// –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
	data := make([]byte, len(value))
	copy(data, value)
	
	item := &cacheItem{
		data:      data,
		expiresAt: time.Now().Add(ttl),
		createdAt: time.Now(),
	}
	
	mc.items[key] = item
	
	mc.logger.Debug("Cache set", 
		"key", key, 
		"data_size", len(value), 
		"ttl", ttl,
		"expires_at", item.expiresAt)
	
	return nil
}

// Delete —É–¥–∞–ª—è–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á—É
func (mc *MemoryCache) Delete(ctx context.Context, key string) error {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	
	_, exists := mc.items[key]
	if exists {
		delete(mc.items, key)
		mc.logger.Debug("Cache delete", "key", key)
	} else {
		mc.logger.Debug("Cache delete - key not found", "key", key)
	}
	
	return nil
}

// Exists –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞
func (mc *MemoryCache) Exists(ctx context.Context, key string) (bool, error) {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()
	
	item, exists := mc.items[key]
	if !exists {
		return false, nil
	}
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å—Ç–µ—á–µ–Ω–∏–µ TTL
	if item.isExpired() {
		// –£–¥–∞–ª—è–µ–º –∏—Å—Ç–µ–∫—à–∏–π —ç–ª–µ–º–µ–Ω—Ç
		mc.mutex.RUnlock()
		mc.mutex.Lock()
		delete(mc.items, key)
		mc.mutex.Unlock()
		mc.mutex.RLock()
		
		return false, nil
	}
	
	return true, nil
}

// SetNX —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª—é—á –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
func (mc *MemoryCache) SetNX(ctx context.Context, key string, value []byte, ttl time.Duration) (bool, error) {
	if ttl <= 0 {
		return false, cache.ErrInvalidTTL
	}
	
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	
	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–∞
	item, exists := mc.items[key]
	if exists && !item.isExpired() {
		mc.logger.Debug("Cache SetNX - key already exists", "key", key)
		return false, nil // –ö–ª—é—á —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
	}
	
	// –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
	data := make([]byte, len(value))
	copy(data, value)
	
	newItem := &cacheItem{
		data:      data,
		expiresAt: time.Now().Add(ttl),
		createdAt: time.Now(),
	}
	
	mc.items[key] = newItem
	
	mc.logger.Debug("Cache SetNX success", 
		"key", key, 
		"data_size", len(value), 
		"ttl", ttl)
	
	return true, nil
}

// Expire —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç TTL –¥–ª—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–ª—é—á–∞
func (mc *MemoryCache) Expire(ctx context.Context, key string, ttl time.Duration) error {
	if ttl <= 0 {
		return cache.ErrInvalidTTL
	}
	
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	
	item, exists := mc.items[key]
	if !exists {
		mc.logger.Debug("Cache expire - key not found", "key", key)
		return cache.ErrCacheKeyNotFound
	}
	
	if item.isExpired() {
		delete(mc.items, key)
		return cache.ErrCacheKeyNotFound
	}
	
	// –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –∏—Å—Ç–µ—á–µ–Ω–∏—è
	item.expiresAt = time.Now().Add(ttl)
	
	mc.logger.Debug("Cache expire updated", 
		"key", key, 
		"new_ttl", ttl,
		"expires_at", item.expiresAt)
	
	return nil
}

// Keys –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–ª—é—á–∏ –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É
// –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω–æ–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –∫—ç—à–µ–π!
func (mc *MemoryCache) Keys(ctx context.Context, pattern string) ([]string, error) {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()
	
	var matchingKeys []string
	
	for key, item := range mc.items {
		// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏—Å—Ç–µ–∫—à–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
		if item.isExpired() {
			continue
		}
		
		// –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ * –≤ –∫–æ–Ω—Ü–µ)
		if matchesPattern(key, pattern) {
			matchingKeys = append(matchingKeys, key)
		}
	}
	
	mc.logger.Debug("Cache keys search", 
		"pattern", pattern, 
		"found_count", len(matchingKeys))
	
	return matchingKeys, nil
}

// FlushAll –æ—á–∏—â–∞–µ—Ç –≤–µ—Å—å –∫—ç—à
// –í–ù–ò–ú–ê–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤!
func (mc *MemoryCache) FlushAll(ctx context.Context) error {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	
	itemCount := len(mc.items)
	mc.items = make(map[string]*cacheItem)
	
	// –°–±—Ä–∞—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
	mc.metrics.mutex.Lock()
	mc.metrics.hits = 0
	mc.metrics.misses = 0
	mc.metrics.errors = 0
	mc.metrics.mutex.Unlock()
	
	mc.logger.Warn("Cache flushed", "deleted_items", itemCount)
	
	return nil
}

// –§–û–ù–û–í–ê–Ø –û–ß–ò–°–¢–ö–ê –ò–°–¢–ï–ö–®–ò–• –≠–õ–ï–ú–ï–ù–¢–û–í

// startCleanup –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ—á–∏—Å—Ç–∫—É –∏—Å—Ç–µ–∫—à–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
func (mc *MemoryCache) startCleanup() {
	ticker := time.NewTicker(mc.cleanupInterval)
	defer ticker.Stop()
	
	mc.logger.Info("Cache cleanup started", "interval", mc.cleanupInterval)
	
	for {
		select {
		case <-ticker.C:
			mc.cleanupExpired()
		case <-mc.stopCleanup:
			mc.logger.Info("Cache cleanup stopped")
			return
		}
	}
}

// cleanupExpired —É–¥–∞–ª—è–µ—Ç –∏—Å—Ç–µ–∫—à–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
func (mc *MemoryCache) cleanupExpired() {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	
	now := time.Now()
	deletedCount := 0
	
	for key, item := range mc.items {
		if now.After(item.expiresAt) {
			delete(mc.items, key)
			deletedCount++
		}
	}
	
	if deletedCount > 0 {
		mc.logger.Debug("Cache cleanup completed", 
			"deleted_items", deletedCount,
			"remaining_items", len(mc.items))
	}
}

// Stop –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Ñ–æ–Ω–æ–≤—É—é –æ—á–∏—Å—Ç–∫—É
func (mc *MemoryCache) Stop() {
	close(mc.stopCleanup)
}

// –ú–ï–¢–†–ò–ö–ò –ö–≠–®–ê

// recordHit –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ –∫—ç—à
func (mc *MemoryCache) recordHit() {
	mc.metrics.mutex.Lock()
	mc.metrics.hits++
	mc.metrics.mutex.Unlock()
}

// recordMiss –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–º–∞—Ö –∫—ç—à–∞
func (mc *MemoryCache) recordMiss() {
	mc.metrics.mutex.Lock()
	mc.metrics.misses++
	mc.metrics.mutex.Unlock()
}

// recordError –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ—à–∏–±–∫—É –∫—ç—à–∞
func (mc *MemoryCache) recordError() {
	mc.metrics.mutex.Lock()
	mc.metrics.errors++
	mc.metrics.mutex.Unlock()
}

// GetMetrics –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫—ç—à–∞
func (mc *MemoryCache) GetMetrics() cache.CacheMetrics {
	mc.metrics.mutex.RLock()
	defer mc.metrics.mutex.RUnlock()
	
	return cache.CacheMetrics{
		Hits:   mc.metrics.hits,
		Misses: mc.metrics.misses,
		Errors: mc.metrics.errors,
	}
}

// GetStats –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
func (mc *MemoryCache) GetStats() map[string]interface{} {
	mc.mutex.RLock()
	defer mc.mutex.RUnlock()
	
	mc.metrics.mutex.RLock()
	defer mc.metrics.mutex.RUnlock()
	
	totalMemory := 0
	expiredItems := 0
	now := time.Now()
	
	for _, item := range mc.items {
		totalMemory += len(item.data)
		if now.After(item.expiresAt) {
			expiredItems++
		}
	}
	
	metrics := mc.GetMetrics()
	
	return map[string]interface{}{
		"total_items":    len(mc.items),
		"expired_items":  expiredItems,
		"memory_bytes":   totalMemory,
		"hits":           metrics.Hits,
		"misses":         metrics.Misses,
		"errors":         metrics.Errors,
		"hit_ratio":      metrics.HitRatio(),
	}
}

// UTILITY FUNCTIONS

// matchesPattern –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–ª—é—á–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—É
func matchesPattern(key, pattern string) bool {
	// –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ * –≤ –∫–æ–Ω—Ü–µ
	if pattern == "*" {
		return true
	}
	
	if strings.HasSuffix(pattern, "*") {
		prefix := strings.TrimSuffix(pattern, "*")
		return strings.HasPrefix(key, prefix)
	}
	
	return key == pattern
}

// –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø –î–õ–Ø PRODUCTION

// MemoryCacheConfig –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è memory cache
type MemoryCacheConfig struct {
	CleanupInterval time.Duration `yaml:"cleanup_interval" env:"MEMORY_CACHE_CLEANUP_INTERVAL" default:"5m"`
	MaxItems        int           `yaml:"max_items" env:"MEMORY_CACHE_MAX_ITEMS" default:"10000"`
	MaxMemoryMB     int           `yaml:"max_memory_mb" env:"MEMORY_CACHE_MAX_MEMORY_MB" default:"100"`
}

// –ü–†–ò–ú–ï–ß–ê–ù–ò–Ø –ü–û PRODUCTION:
// 1. –î–ª—è production –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Redis –≤–º–µ—Å—Ç–æ memory cache
// 2. Memory cache –ø–æ–¥—Ö–æ–¥–∏—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è single-instance –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
// 3. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
// 4. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ TTL –¥–ª—è –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
// 5. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ LRU eviction policy –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–∞–º—è—Ç–∏

// –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:

/*
// –í main.go –∏–ª–∏ DI container:
func initCache(logger logger.Logger) cache.Cache {
    // –î–ª—è development
    if env == "development" {
        return cache.NewMemoryCache(logger, 5*time.Minute)
    }
    
    // –î–ª—è production
    return redis.NewRedisCache(redisConfig, logger)
}

// –í Use Case:
type LoginUseCase struct {
    userRepo user.Repository // CachingUserRepository
    // –∫—ç—à –∏–Ω–∫–∞–ø—Å—É–ª–∏—Ä–æ–≤–∞–Ω –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏
}

// –í Repository:
userCache := cache.NewUserCache(cacheInstance)
cachingRepo := cache.NewCachingUserRepository(baseRepo, userCache, 10*time.Minute)
*/